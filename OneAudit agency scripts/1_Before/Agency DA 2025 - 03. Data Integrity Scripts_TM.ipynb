{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44066100-a275-4505-b1e0-dfa1dfb84517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 25HK010BN - Distribution - Agency - Data analytics review on Agency Pre-sales Controls (Python / Databricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76b00295-80ac-488c-b169-66b91500bac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### import packages / files from Sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47bb6b83-fbf3-416d-8a36-2eca35d1ae2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066166ca-7c54-4614-a4b3-ba4e39b5cf12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read param file from GIA blob \n",
    "df_param = pd.read_excel('/Volumes/aiahk_dna_p_catalog/dna_gia_blob/gia_blob_volume/Agency_PD/parameters.xlsx', engine='openpyxl', index_col='param_name')\n",
    "df_param.loc['review_period_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6358828-2f20-4867-af69-948e1b708238",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "711cf988-9d2f-4a5f-a369-99003b190281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def is_invalid_date(date_str):\n",
    "    # Return True if date_str is null, empty, or not a valid date after 1902-01-01\n",
    "    if pd.isnull(date_str) or str(date_str).strip() == '':\n",
    "        return True\n",
    "    if str(date_str)[0:10] >= '2099-12-31':\n",
    "        return False\n",
    "    try:\n",
    "        dt = pd.to_datetime(date_str, errors='coerce')\n",
    "        if pd.isnull(dt):\n",
    "            return True\n",
    "        if dt <= pd.Timestamp('1902-01-01'):\n",
    "            return True\n",
    "        # Check for invalid year, month, or day\n",
    "        if dt.year < 1902 or dt.month < 1 or dt.month > 12 or dt.day < 1 or dt.day > 31:\n",
    "            return True\n",
    "    except Exception:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbb415e7-a197-4f1d-983b-2e362620c394",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Data integrity scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd84db33-c7df-46f4-b767-1ce3cb974bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_001 Identify agents with blank or invalid agent contract dates (with date format other than 'YYYY-MM-DD' or earlier than '1902-01-01') on DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22ac99b6-d147-4b4f-b7e6-3ad245845b6a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755248061000}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI001 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE AGT_STATUS = '00' or AGT_STATUS = '10' -- inforce agents\n",
    "        OR (TERMINATION_DT >= '{df_param.loc[\"review_period_start\"][\"param_value\"]}' -- filter: termination date after review period start\n",
    "          AND TERMINATION_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}' -- filter: termination date before review period end\n",
    "        )\n",
    "    ) agt_mas\n",
    "    LEFT JOIN (\n",
    "        SELECT * \n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        WHERE LICENSE_TYPE = '03' -- filter: license type 03 (life)\n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI001_ps = df_DI001.pandas_api()\n",
    "display(df_DI001_ps)\n",
    "display(df_DI001_ps.shape[0])\n",
    "\n",
    "# df_DI001.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34346649-9621-4b4a-bd02-bc5ab53adf26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI001_ps['invalid_contract_date'] = df_DI001_ps['AGT_CONTRACT_DT'].apply(is_invalid_date)\n",
    "display(df_DI001_ps.head())\n",
    "df_DI001_exception = df_DI001_ps[df_DI001_ps['invalid_contract_date']]\n",
    "display(df_DI001_exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73009fce-5088-4372-b077-ca6f3bdcad01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6bc5371-7050-473e-bcd6-35ff07a97acc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# output exceptions to table \n",
    "if len(df_DI001_exception) > 0:\n",
    "    df_to_write = df_DI001_exception\n",
    "else:\n",
    "    df_to_write = ps.DataFrame([], columns=df_DI001_exception.columns)\n",
    "    \n",
    "# Write df_to_write to table with mergeSchema option\n",
    "df_to_write.to_table('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI001',mode='overwrite', overwrite_schema=True,**{\n",
    "        \"mergeSchema\": \"true\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6e664c-dc66-4d63-803e-d2c0b3be47b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_002 Identify agents with blank or invalid agent termination dates (with date format other than 'YYYY-MM-DD' or earlier than '1902-01-01') on DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525a7383-727d-48de-9570-1b33133ba309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI002 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE AGT_STATUS NOT IN ('00','10') \n",
    "        )\n",
    "     agt_mas\n",
    "    LEFT JOIN (\n",
    "        SELECT * \n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        WHERE LICENSE_TYPE = '03' -- filter: license type 03 (life)\n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI002_ps = df_DI002.pandas_api()\n",
    "display(df_DI002_ps)\n",
    "display(df_DI002_ps.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b434c6ec-9ec1-45b4-92eb-6381c4341f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI002_ps['invalid_term_date'] = df_DI002_ps['TERMINATION_DT'].apply(is_invalid_date)\n",
    "display(df_DI002_ps.head())\n",
    "df_DI002_exception = df_DI002_ps[df_DI002_ps['invalid_term_date']]\n",
    "display(df_DI002_exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e512878f-5711-4f76-b791-f47eb2352333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# output exceptions to table \n",
    "if len(df_DI002_exception) > 0:\n",
    "    df_to_write = df_DI002_exception\n",
    "else:\n",
    "    df_to_write = ps.DataFrame([], columns=df_DI002_exception.columns)\n",
    "    \n",
    "# Write df_to_write to table with mergeSchema option\n",
    "df_to_write.to_table('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI002',mode='overwrite',overwrite_schema=True,**{\n",
    "        \"mergeSchema\": \"true\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2a67f1f-2d0a-4744-9cba-9aae50640ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_003 Identify agents with contract dates later than start dates of any policies sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fca526d-9184-450a-99cc-60034f109f2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI003 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO, UI.*\n",
    "    FROM (\n",
    "       SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE AGT_STATUS = '00' or AGT_STATUS = '10' -- inforce agents\n",
    "        OR (TERMINATION_DT >= '{df_param.loc[\"review_period_start\"][\"param_value\"]}' -- filter: termination date after review period start\n",
    "          AND TERMINATION_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}' -- filter: termination date before review period end\n",
    "        )\n",
    "    )\n",
    "     agt_mas\n",
    "    LEFT JOIN (\n",
    "        SELECT * \n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        WHERE LICENSE_TYPE = '03' -- filter: license type 03 (life)\n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    LEFT JOIN (\n",
    "        SELECT AGT_CODE, MIN(app_date) AS earliest_app_date, \n",
    "               COLLECT_SET(UI_POL.POLICY_NO)[0] AS earliest_policy_no\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._ui_policy_app_review_period ui_pol\n",
    "        INNER JOIN\n",
    "        aiahk_dna_p_catalog.dna_gia_blob._ui_policy_app_review_period_agt_mapping ui_mapping\n",
    "        ON ui_pol.POLICY_NO = ui_mapping.POLICY_NO\n",
    "        GROUP BY ui_mapping.AGT_CODE\n",
    "    ) UI\n",
    "    ON UI.AGT_CODE = agt_mas.AGT_CD\n",
    "    WHERE UI.earliest_app_date < agt_mas.AGT_CONTRACT_DT\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI003_ps = df_DI003.pandas_api()\n",
    "display(df_DI003_ps)\n",
    "display(df_DI003_ps.shape[0])\n",
    "\n",
    "df_DI003.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI003')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa50024b-fed8-4dcd-8ef9-3e2e93419dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_004 Identify terminiated agents with termination date earlier than agent contract date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42f100fb-e1d4-4be1-911d-da994d5fd36b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI004 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE AGT_STATUS NOT IN ('00','10') \n",
    "        )\n",
    "     agt_mas\n",
    "    LEFT JOIN (\n",
    "        SELECT * \n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        WHERE LICENSE_TYPE = '03' -- filter: license type 03 (life)\n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    WHERE TERMINATION_DT < AGT_CONTRACT_DT\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI004_ps = df_DI004.pandas_api()\n",
    "display(df_DI004_ps)\n",
    "display(df_DI004_ps.shape[0])\n",
    "\n",
    "df_DI004.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI004')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14728c05-a86a-4f34-b278-39ded31024fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_005 Identify agents with blank or invalid license effective dates (with date format other than 'YYYY-MM-DD' or earlier than '1902-01-01') on DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7843d322-7bda-4e40-ba41-5d87228af7f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI005 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE AGT_STATUS = '00' or AGT_STATUS = '10' -- inforce agents\n",
    "        OR (TERMINATION_DT >= '{df_param.loc[\"review_period_start\"][\"param_value\"]}' -- filter: termination date after review period start\n",
    "          AND TERMINATION_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}' -- filter: termination date before review period end\n",
    "        )\n",
    "    ) agt_mas\n",
    "    INNER JOIN (\n",
    "        SELECT * \n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    WHERE agt_lic.AGT_CD IS NOT NULL\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI005_ps = df_DI005.pandas_api()\n",
    "display(df_DI005_ps)\n",
    "display(df_DI005_ps.shape[0])\n",
    "\n",
    "# df_DI001.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7591d648-7d8c-4cd9-af37-11e0b6e40816",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755501967724}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI005_ps['invalid_licenseEff_date'] = df_DI005_ps['EFF_DT'].apply(is_invalid_date)\n",
    "display(df_DI005_ps.head())\n",
    "df_DI005_exception = df_DI005_ps[df_DI005_ps['invalid_licenseEff_date']]\n",
    "display(df_DI005_exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b90af25-59f8-430e-a451-72e543a1078d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# output exceptions to table \n",
    "if len(df_DI005_exception) > 0:\n",
    "    df_to_write = df_DI005_exception\n",
    "else:\n",
    "    df_to_write = ps.DataFrame([], columns=df_DI005_exception.columns)\n",
    "    \n",
    "# Write df_to_write to table with mergeSchema option\n",
    "df_to_write.to_table('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI005',mode='overwrite', overwrite_schema=True,**{\n",
    "        \"mergeSchema\": \"true\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ebba82d-fddb-4cd8-913b-48d6b2951755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_006 Identify agents with blank or invalid license expiry dates (with date format other than 'YYYY-MM-DD' or earlier than '1902-01-01') on DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2f970a8-e3ea-4623-911b-7773332a3244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI006_ps = df_DI005_ps[~(df_DI005_ps['EXP_DT']>=pd.Timestamp.max)] ## exclude out of range future dates\n",
    "df_DI006_ps['invalid_licenseExp_date'] = df_DI006_ps['EXP_DT'].apply(is_invalid_date)\n",
    "display(df_DI006_ps.head())\n",
    "df_DI006_exception = df_DI006_ps[df_DI006_ps['invalid_licenseExp_date']]\n",
    "display(df_DI006_exception)\n",
    "\n",
    "# output exceptions to table \n",
    "if len(df_DI006_exception) > 0:\n",
    "    df_to_write = df_DI006_exception\n",
    "else:\n",
    "    df_to_write = ps.DataFrame([], columns=df_DI006_exception.columns)\n",
    "    \n",
    "# Write df_to_write to table with mergeSchema option\n",
    "df_to_write.to_table('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI006',mode='overwrite',overwrite_schema=True,**{\n",
    "        \"mergeSchema\": \"true\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d16410f4-6a83-49af-91b7-920688af7e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_007 Identify agents with blank regulatory license no. on DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2d0df9b-ac12-4f9b-b1a6-b7715861592a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI007 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_lic.MAX_LICENSE_NO\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE AGT_STATUS = '00' or AGT_STATUS = '10' -- inforce agents\n",
    "        OR (TERMINATION_DT >= '{df_param.loc[\"review_period_start\"][\"param_value\"]}' -- filter: termination date after review period start\n",
    "          AND TERMINATION_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}' -- filter: termination date before review period end\n",
    "        )\n",
    "    ) agt_mas\n",
    "    INNER JOIN (\n",
    "        SELECT AGT_CD, max(LICENSE_NO) as MAX_LICENSE_NO\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        WHERE LICENSE_TYPE in ('01','02','03','04','99') \n",
    "        GROUP BY AGT_CD \n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    WHERE agt_lic.AGT_CD IS NOT NULL\n",
    "    AND (MAX_LICENSE_NO IS NULL OR TRIM(MAX_LICENSE_NO) = '')\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI007_ps = df_DI007.pandas_api()\n",
    "display(df_DI007_ps)\n",
    "display(df_DI007_ps.shape[0])\n",
    "\n",
    "df_DI007.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI007')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb8a25b0-0e88-43ee-96cc-5e78e44d0efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_008 Identify agents with blank license flag or other than '0' and '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b520f7a-ad95-4745-9d3b-0f9d794f3e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI008 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_mas.AGT_TYPE_DESC, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO, agt_lic.MAX_GI_LICENSE_IND\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE (AGT_CONTRACT_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}') AND -- exclude agents contracted after review period\n",
    "        (\n",
    "          AGT_STATUS = '00' or AGT_STATUS = '10' -- inforce agents\n",
    "          OR  (TERMINATION_DT >= '{df_param.loc[\"review_period_start\"][\"param_value\"]}' -- filter: termination date after review period start\n",
    "              AND TERMINATION_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}' -- filter: termination date before review period end\n",
    "        ))\n",
    "    ) agt_mas\n",
    "    LEFT JOIN (\n",
    "        SELECT AGT_CD,\n",
    "               MAX(EFF_DT) AS EFF_DT,\n",
    "               MAX(EXP_DT) AS EXP_DT,\n",
    "               MAX(LICENSE_DESC) AS LICENSE_DESC,\n",
    "               MAX(LICENSE_TYPE) AS LICENSE_TYPE,\n",
    "               MAX(LICENSE_NO) AS LICENSE_NO,\n",
    "               MAX(GI_LICENSE_IND) AS MAX_GI_LICENSE_IND\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        GROUP BY AGT_CD\n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    WHERE agt_lic.MAX_GI_LICENSE_IND IS NULL OR trim(agt_lic.MAX_GI_LICENSE_IND) = \"\" OR agt_lic.MAX_GI_LICENSE_IND NOT IN (1,0) \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI008_ps = df_DI008.pandas_api()\n",
    "display(df_DI008_ps)\n",
    "display(df_DI008_ps.shape[0])\n",
    "\n",
    "df_DI008.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI008')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6c08a38-83f6-4d32-af68-25de1c8b6d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### [HK & Macau] DAS_DI_009 Identify agents with blank or null license type code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaba9bed-569c-45e9-8996-5f275ce07495",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_DI009 = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_mas.AGT_CD, agt_mas.AGT_FULL_NAME, agt_mas.CHANNEL_TYPE, agt_mas.REGION, left(agt_mas.AGT_CONTRACT_DT, 10) AS AGT_CONTRACT_DT, agt_mas.AGT_STATUS, agt_mas.TERMINATION_DT, agt_mas.AGT_TYPE_DESC, agt_lic.EFF_DT, agt_lic.EXP_DT, agt_lic.LICENSE_DESC, agt_lic.LICENSE_TYPE, agt_lic.LICENSE_NO, agt_lic.MAX_GI_LICENSE_IND\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        WHERE (AGT_CONTRACT_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}') AND -- exclude agents contracted after review period\n",
    "        (\n",
    "          AGT_STATUS = '00' or AGT_STATUS = '10' -- inforce agents\n",
    "          OR  (TERMINATION_DT >= '{df_param.loc[\"review_period_start\"][\"param_value\"]}' -- filter: termination date after review period start\n",
    "              AND TERMINATION_DT <= '{df_param.loc[\"review_period_end\"][\"param_value\"]}' -- filter: termination date before review period end\n",
    "        ))\n",
    "    ) agt_mas\n",
    "    LEFT JOIN (\n",
    "        SELECT AGT_CD,\n",
    "               MAX(EFF_DT) AS EFF_DT,\n",
    "               MAX(EXP_DT) AS EXP_DT,\n",
    "               MAX(LICENSE_DESC) AS LICENSE_DESC,\n",
    "               MAX(LICENSE_TYPE) AS LICENSE_TYPE,\n",
    "               MAX(LICENSE_NO) AS LICENSE_NO,\n",
    "               MAX(GI_LICENSE_IND) AS MAX_GI_LICENSE_IND\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_license \n",
    "        GROUP BY AGT_CD\n",
    "    ) agt_lic\n",
    "      ON agt_mas.AGT_CD = agt_lic.AGT_CD\n",
    "    WHERE agt_lic.LICENSE_TYPE IS NULL OR trim(agt_lic.LICENSE_TYPE) = \"\"\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# put _sqldf into df_das as pyspark pandas df\n",
    "df_DI009_ps = df_DI009.pandas_api()\n",
    "display(df_DI009_ps)\n",
    "display(df_DI009_ps.shape[0])\n",
    "\n",
    "df_DI009.write.mode('overwrite').option(\"overwriteSchema\", \"True\").saveAsTable('aiahk_dna_p_catalog.dna_gia_blob.ca_agy_DI009')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c6251d5-2873-47b1-b417-ac8a68761054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Summary figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f00ddd62-fda0-42f3-9190-4dbc65d58803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Number of Records Analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda37b9e-acda-47fd-9263-b2bef52cc431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT REGION, count(distinct agt_mas.AGT_CD)\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        where (agt_status in ('00','10') or TERMINATION_DT >= '2025-01-01')\n",
    "    ) agt_mas\n",
    "    GROUP BY REGION\n",
    "    \"\"\"\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb936a56-3490-47a5-9a66-ade5dae34aa4",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"agt_type_desc\":276},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758596736393}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT agt_type_desc, AGT_DUMMY_TYPE, count(distinct agt_mas.AGT_CD)\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "        where (agt_status in ('00','10')) \n",
    " /*       and AGT_TYPE_DESC not like '%Staff%'\n",
    "        and AGT_TYPE_DESC not like '%Intern%'\n",
    "        and AGT_TYPE_DESC not like '%Corporate%'\n",
    "        and AGT_DUMMY_TYPE is null\n",
    "   */ ) agt_mas\n",
    "    group by  agt_type_desc, AGT_DUMMY_TYPE\n",
    "    \"\"\"\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc250a3-03c2-411e-816e-a5aab6e11975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT REGION, count(distinct UI.POLICY_NO)\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob.`_ui_policy_app_review_period` \n",
    "    ) UI\n",
    "    LEFT JOIN \n",
    "      aiahk_dna_p_catalog.dna_gia_blob._ui_policy_app_review_period_agt_mapping agt_map\n",
    "      ON UI.POLICY_NO = agt_map.POLICY_NO\n",
    "    INNER JOIN  \n",
    "    (\n",
    "        SELECT * \n",
    "        FROM aiahk_dna_p_catalog.dna_gia_blob._das_agent_master \n",
    "    ) agt_mas\n",
    "     on agt_map.AGT_CODE = agt_mas.AGT_CD\n",
    "     GROUP BY REGION\n",
    "     \"\"\"\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1bcc302-1a9d-4e0c-94fa-fdc345f078d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Agency DA 2025 - 03. Data Integrity Scripts",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
